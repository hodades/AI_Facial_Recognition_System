{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69f56b76-5add-44f9-95b5-26ce4addca91",
   "metadata": {},
   "source": [
    "# Albert School Facial Recognition System"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a02c04ac-7b4f-4f5e-851e-894e29d3253d",
   "metadata": {},
   "source": [
    "The Albert School currently has a badge entry system to access the school grounds.\n",
    "We propose to the school to continue its IT momentum by replacing this system with a facial recognition system.\n",
    "Here is the prototype:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68c6cb76-cc4b-48f0-9774-3e40042df6fd",
   "metadata": {},
   "source": [
    "## The system"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dc5647b-8f87-4ac0-841e-2b1c66deadb3",
   "metadata": {},
   "source": [
    "So we have the following data base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "33e7d3ae-a3fa-4fcd-a46d-c9bec34a9196",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: facenet_pytorch in ./.venv/lib/python3.12/site-packages (2.6.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.24.0 in ./.venv/lib/python3.12/site-packages (from facenet_pytorch) (1.26.4)\n",
      "Requirement already satisfied: Pillow<10.3.0,>=10.2.0 in ./.venv/lib/python3.12/site-packages (from facenet_pytorch) (10.2.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.0.0 in ./.venv/lib/python3.12/site-packages (from facenet_pytorch) (2.32.3)\n",
      "Requirement already satisfied: torch<2.3.0,>=2.2.0 in ./.venv/lib/python3.12/site-packages (from facenet_pytorch) (2.2.2)\n",
      "Requirement already satisfied: torchvision<0.18.0,>=0.17.0 in ./.venv/lib/python3.12/site-packages (from facenet_pytorch) (0.17.2)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.0.0 in ./.venv/lib/python3.12/site-packages (from facenet_pytorch) (4.66.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.12/site-packages (from requests<3.0.0,>=2.0.0->facenet_pytorch) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.12/site-packages (from requests<3.0.0,>=2.0.0->facenet_pytorch) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.12/site-packages (from requests<3.0.0,>=2.0.0->facenet_pytorch) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.12/site-packages (from requests<3.0.0,>=2.0.0->facenet_pytorch) (2024.8.30)\n",
      "Requirement already satisfied: filelock in ./.venv/lib/python3.12/site-packages (from torch<2.3.0,>=2.2.0->facenet_pytorch) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in ./.venv/lib/python3.12/site-packages (from torch<2.3.0,>=2.2.0->facenet_pytorch) (4.12.2)\n",
      "Requirement already satisfied: sympy in ./.venv/lib/python3.12/site-packages (from torch<2.3.0,>=2.2.0->facenet_pytorch) (1.13.3)\n",
      "Requirement already satisfied: networkx in ./.venv/lib/python3.12/site-packages (from torch<2.3.0,>=2.2.0->facenet_pytorch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in ./.venv/lib/python3.12/site-packages (from torch<2.3.0,>=2.2.0->facenet_pytorch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in ./.venv/lib/python3.12/site-packages (from torch<2.3.0,>=2.2.0->facenet_pytorch) (2024.10.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.12/site-packages (from jinja2->torch<2.3.0,>=2.2.0->facenet_pytorch) (3.0.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./.venv/lib/python3.12/site-packages (from sympy->torch<2.3.0,>=2.2.0->facenet_pytorch) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install facenet_pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5304dc21-ff37-4c31-8b19-6950fa9369a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in ./.venv/lib/python3.12/site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.26.0 in ./.venv/lib/python3.12/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.12/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.venv/lib/python3.12/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0b33e4bb-0abe-46a1-a774-a080dc1e1fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "aaf89251-d56c-415e-b7e4-9c1b9e2062c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>student_id</th>\n",
       "      <th>name</th>\n",
       "      <th>first_name</th>\n",
       "      <th>birth_date</th>\n",
       "      <th>age</th>\n",
       "      <th>path_picture</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Hoda</td>\n",
       "      <td>Dades</td>\n",
       "      <td>12/04/1999</td>\n",
       "      <td>25</td>\n",
       "      <td>hoda_cropped.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Yasmine</td>\n",
       "      <td>Ferdjani</td>\n",
       "      <td>25/08/2000</td>\n",
       "      <td>24</td>\n",
       "      <td>yasmine_cropped.png</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   student_id     name first_name  birth_date  age         path_picture\n",
       "0           1     Hoda      Dades  12/04/1999   25     hoda_cropped.png\n",
       "1           2  Yasmine   Ferdjani  25/08/2000   24  yasmine_cropped.png"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_albert = pd.read_csv('db_student.csv', sep=';')\n",
    "\n",
    "df_albert"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f6fdb9-f92b-420f-91b9-4359031b295f",
   "metadata": {},
   "source": [
    "In this data base we have two students. Each line means an entry in the area of the school.\n",
    "So Hoda and Yasmine cames only once in the school. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ee9d6e38-99fa-4585-a4a5-d4018909f748",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in ./.venv/lib/python3.12/site-packages (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.12/site-packages (from requests) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.12/site-packages (from requests) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.12/site-packages (from requests) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.12/site-packages (from requests) (2024.8.30)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5d2dfd24-74c0-468d-9507-15ccfef8c2c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: watchdog in ./.venv/lib/python3.12/site-packages (5.0.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install watchdog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4bc63d23-e54e-408d-a051-026af339b5ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Résultats de la correspondance :\n",
      "                 folder_image  student_id student_name  match  distance\n",
      "0              yasmine_2.jpeg           1         Hoda  False  1.315818\n",
      "1              yasmine_2.jpeg           2      Yasmine   True  0.467260\n",
      "2            hoda_cropped.png           1         Hoda   True  0.000000\n",
      "3            hoda_cropped.png           2      Yasmine  False  1.277669\n",
      "4   yasmine_cropped copie.png           1         Hoda  False  1.277669\n",
      "5   yasmine_cropped copie.png           2      Yasmine   True  0.000000\n",
      "6         yasmine_cropped.png           1         Hoda  False  1.277669\n",
      "7         yasmine_cropped.png           2      Yasmine   True  0.000000\n",
      "8              moustapha.jpeg           1         Hoda  False  1.219394\n",
      "9              moustapha.jpeg           2      Yasmine  False  1.461664\n",
      "10   hoda_cropped copie 2.png           1         Hoda   True  0.000000\n",
      "11   hoda_cropped copie 2.png           2      Yasmine  False  1.277669\n",
      "12     hoda_cropped copie.png           1         Hoda   True  0.000000\n",
      "13     hoda_cropped copie.png           2      Yasmine  False  1.277669\n",
      "\n",
      "Étudiants correspondants :\n",
      "   student_id     name first_name  birth_date  age         path_picture\n",
      "0           2  Yasmine   Ferdjani  25/08/2000   24  yasmine_cropped.png\n",
      "1           1     Hoda      Dades  12/04/1999   25     hoda_cropped.png\n",
      "2           2  Yasmine   Ferdjani  25/08/2000   24  yasmine_cropped.png\n",
      "3           2  Yasmine   Ferdjani  25/08/2000   24  yasmine_cropped.png\n",
      "4           1     Hoda      Dades  12/04/1999   25     hoda_cropped.png\n",
      "5           1     Hoda      Dades  12/04/1999   25     hoda_cropped.png\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from facenet_pytorch import MTCNN, InceptionResnetV1\n",
    "from PIL import Image\n",
    "import torch\n",
    "\n",
    "# Initialisation de MTCNN pour la détection faciale et InceptionResnetV1 pour les embeddings\n",
    "mtcnn = MTCNN()\n",
    "resnet = InceptionResnetV1(pretrained='vggface2').eval()\n",
    "\n",
    "def compare_images(img1_path, img2_path, threshold=0.8):\n",
    "    \"\"\"\n",
    "    Compare deux images en calculant la distance entre leurs embeddings faciaux.\n",
    "    \"\"\"\n",
    "    \n",
    "    img1 = Image.open(img1_path)\n",
    "    img2 = Image.open(img2_path)\n",
    "    \n",
    "    # Détecter et recadrer les visages dans les deux images\n",
    "    img1_cropped = mtcnn(img1)\n",
    "    img2_cropped = mtcnn(img2)\n",
    "    \n",
    "    if img1_cropped is None or img2_cropped is None:\n",
    "        print(\"Erreur : visage non détecté dans l'une des images.\")\n",
    "        return False, None\n",
    "    \n",
    "    # Calculer les embeddings des deux images\n",
    "    img1_embedding = resnet(img1_cropped.unsqueeze(0))\n",
    "    img2_embedding = resnet(img2_cropped.unsqueeze(0))\n",
    "    \n",
    "    # Calculer la distance entre les deux embeddings (distance Euclidienne)\n",
    "    distance = torch.dist(img1_embedding, img2_embedding).item()\n",
    "    \n",
    "    # Comparer la distance avec le seuil\n",
    "    return distance < threshold, distance\n",
    "\n",
    "def compare_folder_to_df(folder_path, df, threshold=0.8):\n",
    "    \"\"\"\n",
    "    Compare chaque photo dans un dossier avec les photos de la DataFrame.\n",
    "    \n",
    "    Args:\n",
    "    - folder_path: Chemin vers le dossier contenant les photos à comparer.\n",
    "    - df: DataFrame contenant les informations des étudiants avec les chemins des photos.\n",
    "    - threshold: Seuil pour déterminer si les visages correspondent.\n",
    "    \n",
    "    Returns:\n",
    "    - Une liste de résultats de correspondance pour chaque photo dans le dossier.\n",
    "    \"\"\"\n",
    "    \n",
    "    results = []\n",
    "    entry_in_campus = []\n",
    "    valid_extensions = ('.jpg', '.jpeg', '.png')  # Extensions de fichiers image valides\n",
    "    \n",
    "    # Parcourir toutes les images dans le dossier\n",
    "    for img_file in os.listdir(folder_path):\n",
    "        # Ignorer les fichiers qui ne sont pas des images\n",
    "        if not img_file.lower().endswith(valid_extensions):\n",
    "            continue\n",
    "        \n",
    "        img_path = os.path.join(folder_path, img_file)\n",
    "        \n",
    "        # Comparer avec chaque image dans la DataFrame\n",
    "        for idx, row in df.iterrows():\n",
    "            ref_img_path = row['path_picture']\n",
    "            \n",
    "            # Comparer l'image du dossier avec celle de la DataFrame\n",
    "            match, distance = compare_images(img_path, ref_img_path, threshold)\n",
    "            \n",
    "            # Ajouter le résultat dans la liste des résultats\n",
    "            results.append({\n",
    "                'folder_image': img_file,\n",
    "                'student_id': row['student_id'],\n",
    "                'student_name': row['name'],\n",
    "                'match': match,\n",
    "                'distance': distance\n",
    "            })\n",
    "            \n",
    "            # Si une correspondance est trouvée, ajouter les informations de l'étudiant\n",
    "            if match:\n",
    "                entry_in_campus.append({\n",
    "                    'student_id': row['student_id'],\n",
    "                    'name': row['name'],\n",
    "                    'first_name': row['first_name'],\n",
    "                    'birth_date': row['birth_date'],\n",
    "                    'age': row['age'],\n",
    "                    'path_picture': row['path_picture']\n",
    "                })\n",
    "    \n",
    "    # Retourner les résultats des correspondances et la liste des étudiants correspondants\n",
    "    results_df = pd.DataFrame(results)\n",
    "    entry_in_campus_df = pd.DataFrame(entry_in_campus)\n",
    "    \n",
    "    return results_df, entry_in_campus_df\n",
    "\n",
    "# Exemple d'utilisation\n",
    "folder_path = 'pictures_from_entry' \n",
    "\n",
    "# Comparaison des photos du dossier avec la base de données\n",
    "result_df, entry_in_campus_df = compare_folder_to_df(folder_path, df_albert)\n",
    "\n",
    "# Afficher les résultats\n",
    "print(\"Résultats de la correspondance :\")\n",
    "print(result_df)\n",
    "\n",
    "print(\"\\nÉtudiants correspondants :\")\n",
    "print(entry_in_campus_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6fc5e97f-9cd5-432c-a994-d80f406db2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "entry_in_campus_df.to_csv('entry_in_campus.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b0841605-b6d2-49c6-a516-88cae77c7c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install flask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "456e03e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "from IPython.display import display\n",
    "from ipywidgets import Button, Output\n",
    "\n",
    "output = Output()\n",
    "\n",
    "# Cette fonction sera appelée lorsqu'un signal WebSocket est reçu\n",
    "async def execute_cell_on_trigger():\n",
    "    with output:\n",
    "        print(\"Photo taken! Executing the Python code...\")\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "from facenet_pytorch import MTCNN, InceptionResnetV1\n",
    "from PIL import Image\n",
    "import torch\n",
    "\n",
    "# Initialisation de MTCNN pour la détection faciale et InceptionResnetV1 pour les embeddings\n",
    "mtcnn = MTCNN()\n",
    "resnet = InceptionResnetV1(pretrained='vggface2').eval()\n",
    "\n",
    "def compare_images(img1_path, img2_path, threshold=0.8):\n",
    "    \"\"\"\n",
    "    Compare deux images en calculant la distance entre leurs embeddings faciaux.\n",
    "    \"\"\"\n",
    "    \n",
    "    img1 = Image.open(img1_path)\n",
    "    img2 = Image.open(img2_path)\n",
    "    \n",
    "    # Détecter et recadrer les visages dans les deux images\n",
    "    img1_cropped = mtcnn(img1)\n",
    "    img2_cropped = mtcnn(img2)\n",
    "    \n",
    "    if img1_cropped is None or img2_cropped is None:\n",
    "        print(\"Erreur : visage non détecté dans l'une des images.\")\n",
    "        return False, None\n",
    "    \n",
    "    # Calculer les embeddings des deux images\n",
    "    img1_embedding = resnet(img1_cropped.unsqueeze(0))\n",
    "    img2_embedding = resnet(img2_cropped.unsqueeze(0))\n",
    "    \n",
    "    # Calculer la distance entre les deux embeddings (distance Euclidienne)\n",
    "    distance = torch.dist(img1_embedding, img2_embedding).item()\n",
    "    \n",
    "    # Comparer la distance avec le seuil\n",
    "    return distance < threshold, distance\n",
    "\n",
    "def compare_folder_to_df(folder_path, df, threshold=0.8):\n",
    "    \"\"\"\n",
    "    Compare chaque photo dans un dossier avec les photos de la DataFrame.\n",
    "    \n",
    "    Args:\n",
    "    - folder_path: Chemin vers le dossier contenant les photos à comparer.\n",
    "    - df: DataFrame contenant les informations des étudiants avec les chemins des photos.\n",
    "    - threshold: Seuil pour déterminer si les visages correspondent.\n",
    "    \n",
    "    Returns:\n",
    "    - Une liste de résultats de correspondance pour chaque photo dans le dossier.\n",
    "    \"\"\"\n",
    "    \n",
    "    results = []\n",
    "    entry_in_campus = []\n",
    "    valid_extensions = ('.jpg', '.jpeg', '.png')  # Extensions de fichiers image valides\n",
    "    \n",
    "    # Parcourir toutes les images dans le dossier\n",
    "    for img_file in os.listdir(folder_path):\n",
    "        # Ignorer les fichiers qui ne sont pas des images\n",
    "        if not img_file.lower().endswith(valid_extensions):\n",
    "            continue\n",
    "        \n",
    "        img_path = os.path.join(folder_path, img_file)\n",
    "        \n",
    "        # Comparer avec chaque image dans la DataFrame\n",
    "        for idx, row in df.iterrows():\n",
    "            ref_img_path = row['path_picture']\n",
    "            \n",
    "            # Comparer l'image du dossier avec celle de la DataFrame\n",
    "            match, distance = compare_images(img_path, ref_img_path, threshold)\n",
    "            \n",
    "            # Ajouter le résultat dans la liste des résultats\n",
    "            results.append({\n",
    "                'folder_image': img_file,\n",
    "                'student_id': row['student_id'],\n",
    "                'student_name': row['name'],\n",
    "                'match': match,\n",
    "                'distance': distance\n",
    "            })\n",
    "            \n",
    "            # Si une correspondance est trouvée, ajouter les informations de l'étudiant\n",
    "            if match:\n",
    "                entry_in_campus.append({\n",
    "                    'student_id': row['student_id'],\n",
    "                    'name': row['name'],\n",
    "                    'first_name': row['first_name'],\n",
    "                    'birth_date': row['birth_date'],\n",
    "                    'age': row['age'],\n",
    "                    'path_picture': row['path_picture']\n",
    "                })\n",
    "    \n",
    "    # Retourner les résultats des correspondances et la liste des étudiants correspondants\n",
    "    results_df = pd.DataFrame(results)\n",
    "    entry_in_campus_df = pd.DataFrame(entry_in_campus)\n",
    "    \n",
    "    return results_df, entry_in_campus_df\n",
    "\n",
    "# Exemple d'utilisation\n",
    "folder_path = 'pictures_from_entry' \n",
    "\n",
    "# Comparaison des photos du dossier avec la base de données\n",
    "result_df, entry_in_campus_df = compare_folder_to_df(folder_path, df_albert)\n",
    "\n",
    "# Afficher les résultats\n",
    "print(\"Résultats de la correspondance :\")\n",
    "print(result_df)\n",
    "\n",
    "print(\"\\nÉtudiants correspondants :\")\n",
    "print(entry_in_campus_df)\n",
    "\n",
    "display(output)\n",
    "\n",
    "# Code pour surveiller les WebSocket (le WebSocket doit être configuré pour communiquer avec le HTML)\n",
    "import websockets\n",
    "\n",
    "async def listen():\n",
    "    uri = \"ws://localhost:8888\"  # L'URL du WebSocket\n",
    "    async with websockets.connect(uri) as websocket:\n",
    "        while True:\n",
    "            message = await websocket.recv()\n",
    "            if message == '{\"action\": \"take_photo_trigger\"}':\n",
    "                await execute_cell_on_trigger()\n",
    "\n",
    "# Lancer la boucle WebSocket\n",
    "asyncio.get_event_loop().run_until_complete(listen())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
